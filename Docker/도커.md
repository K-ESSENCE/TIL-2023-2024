# 도커

1. 도커 클라이언트에 docker run 이미지 입력해주고

1. 도커 이미지에 있는 파일 스냅샷을 컨테이너 하드 디스크에 옮겨줌

1. 이미지에서 가지고 있는 명령어 를 이용해 실행

## 도커 이미지 생성하는 순서

현재까지는 도커 이미지를 도커 허브에 이미 있던 것만 가져와서 사용했음

그러나 직접 만들수도있고 만든걸 올려서 공유할 수 도있다.

- 도커 이미지 복습

도커이미지? 컨테이너를 만들기 위해 필요한 설정이나 종속성을 갖고 있는 소프트웨어 패키지

docker create <이미지 이름>

컨테이너는 도커 이미지로 생성 도커이미지는 어떻게 생성?

도커 파일 작성 → 도커 클라이언트 → 도커 서버 → 이미지 생성

도커파일? : 도커 이미지를 만들기위한 설정파일

도커 클라이언트? : 도커 파일에 입력된 명령어들이 도커 클라이언트에 전달되어야 함

도커 서버? : 도커 클라이언트에 전달된 모든 중요한 작업들을 하는 곳

## Dockerfile 만들기

### 도커 파일 이란?

도커 이미지를 만들기 위한 설정 파일이며 어떻게 행동해야되는지 설정 정의하는곳

### 도커 파일 만드는 순서

1. 베이스 이미지 명시 (파일 스냅샷)
2. 추가적으로 필요한 파일을 다운 받기 위한 몇가지 명령어 명시 (파일 스냅샷)
3. 컨테이너 시작시 실행명령 작성

### 베이스 이미지?

도커 이미지는 여러개의 레이어들로 되어있음

베이스 이미지는 이 이미지의 기반이 되는 부분

레이어는 중간 단계의 이미지

레이어가 많이 쌓여서 이미지가 된다.

베이스 이미지는 간단하게 OS라고 생각하면 됨

이 이미지에 뭔가 추가한다면 레이어가 이미지에 추가되며 레이어 캐싱이라고 부름

뭔가가 이미지에 레이어가 추가되며 레이어캐싱이라한다.

//dockerfile

```docker
# 베이스 이미지 명시

FROM baseImage

# 추가적으로 필요한 파일 다운

RUN command

# 컨테이너 시작 시 실행 될 명령어를 명시해준다.

CMD [ "executable" ]
```

base 우분투 해도 되는데 이번 의 경우 hello world 할거라서 그냥 alpine

## Docker 이미지 & 컨테이너

### 외부 이미지 사용

docker run 해서 실행은 시켰지만 그것만해서는 의미가없음 외부에 노출이안됨

docker run -it node 명령어

it명령어? => 도커에게 컨테이너 내부에서 호스팅 머신으로 대화형 세션을 노출하고 싶다고 알리는 것

docker run -it node 하면 실제로 명령어 입력가능 .

중요한것은 노드가 생성된 컨테이너 내부에서 실행중이고 플래그를 통해서 실행중인 노드와 상호작용할 수 있다는것.

docker ps -a

이미지에는 코드 설정 등 여러가지가 포함됨 / 컨테이너는 그 이미지의 실행 인스턴스다.

### 도커파일 이용해서 자체 이미지 빌드

도커 익스텐션 설치 언제깔았지

도커파일에는 자체이미지를 빌드할때 실행하려는 도커에대한 명령어가 포함됨

자체이미지에대한 설정도 포함
FROM 가지고오고싶은 툴
COPY . . => 첫번째 경로는 컨테이너 외부 이미지의 외부경로 이미지가 복사되어야할 파일들이 있는곳임.

그냥 . 을 넣으면 도커파일이있는 폴더와 동일한 폴더임을 가리킨다. (Dockerfile 제외)

두번째 . 는 파일을 저장해야되는 이미지 내부의 경로.

모든 이미지와 이미지를 기반으로 생성된 모든 컨테이너에는 로컬 머신의 파일 시스템에서 완전히 분리된 자체 내부 파일 시스템이 있음.

첫번째는 import 두번쨰는
export 폴더라고 이해했다.

컴파일시킬 파일들과 그게 export 되는 컨테이너 내부 경로

RUN => 실행할 명령어

WORKDIR 도커 컨테이너의 작업 디렉토리 설정하는 명령어=> 모든 후속 명령이 그 폴더안에서 실행되도록.

RUN node server.js
라고 하는건 올바르지않음 이미지가 빌드될때마다 실행되기 때문

dockerfile에 있는 모든것은 이미지 설정을 위한 도커에대한 명령임.

이미지는 컨테이너의 템플릿이라는것을 잊지마라.

이미지를 기반으로 컨테이너를 실행하는것임
RUN으로 하면 만들때마다 서버가 실행됨

CMD 명령어 => 이미지가 생성될때 실행되는게 아니라 이미지를 기반으로 컨테이너가 실행될때 나오는 명령어
단지 cmd의 경우 배열로 해서 나눠실행

EXPOSE 노출시킬 port

작성한 전체 도커파일

```
FROM node:latest


WORKDIR /src

COPY . /src

RUN npm i

EXPOSE 80

CMD ["node","server.js"]



```

docker build .
마지막은 경로. 지금내가 있는곳과 같으면 그냥 .

성공하면 images 명령어로 볼 수 있음

그 아이디 들고 docker run id 하면됨

-a 없이 docker ps 하면 실행중인것만 볼 수있다.

docker stop id

껐으니 ps-a옵션으로볼수있음

위와같은 단계로 실행해도 localhost:80으로 접근이안됨

실행할때 docker run -p 로 실행시키면 어떤 로컬 포트가있는지 도커에게 알려줘야됨.

docker -p 로컬포트:노출포트(이경우 80)

결국 Dockerfile 의 Expose 80은 옵션이지만 포트를 노출할것이라는 명시적 문서화.하는 모범사례

- 이미지는 읽기 전용이다.

코드를 변경하고 도커 이미지를 끄고 다시 실행했는데도 왜 변경사항이 적용되지않는가?

빌드를 다시해야지 이미지 껐다켜봐야 의미없는게아닌가=> 맞음 다시빌드해야됨

기본적으로 복사한 시점에서 소스코드의 스냅샷을 만듦 => 변경사항은 소스코드에 포함되지않음

지우건 말건 이미지는 아무 신경 안씀.

만든 순간 고정이다.

### 이미지 레이어

이미지는 레이어 기반이다.

레이어 기반?=> 이미지를 빌드하거나 다시 빌드할때 변경된 부분의 명령과 그 이후의 모든 명령어는 재평가된다.

docker build . 해서 다시 이미지를 빌드하면 매우 빠르게 완료된다.

Using cache => 도커는 기본적으로 다시 실행했을때의 결과가 똑같다는것을 인지했기 때문

이미지를 빌드할때마다 모든 명령 결과를 캐시하고

이미지를 다시 빌드할때 다시 실행할 필요가없으면 캐시된 결과를 사용함.

이걸 레이어 기반 아키텍쳐라고함.

모든 명령은 dockerfile의 레이어를 나타냄

이미지는 다양한 명령을 기반으로 여러 레이어에서 간단히 구성되며 readonly임

다시빌드하지않는한.

이미지를 기반으로 컨테이너를 실행하면 컨테이너는 기본적으로 dockerfile을 기반으로 실행해서 새로운 컨테이너 레이어를 만듦
컨테이너레이어는 read-write

명령어 하나하나는 이미지의 일부이면서 별도의 레이어이기도하다.

그리고 변경점이없으면 이모든 레이어를 캐시에서 사용할수있다.

- FORM 레이어
- WORKDIR 레이어
  이런식으로 있고 캐시되면 쓴다 그래서 레이어아키텍쳐다 그렇게 이해

레이어 하나가 변경되면 후속 레이어도 다시 실행된다.

그래서 COPY에서 파일이 바뀌면 그뒤 npm install 도 다시 실행

종속성의 경우에는 파일이 바뀐다고 다시 설치할 필요가없음 이를 최적화하기위해서는

npm i 하기전에 COPY를 한번 더 하는거

```
COPY package.json /app

RUN npm install

COPY ./ app
```

이렇게 레이어하나 추가해서 npm install은 다시 실행되지않게 바꿀수있다.
npm install은 무거우니까.

컨테이너는 이미지위에 얇게 펼쳐진 레이어

컨테이너가 이미지에서 코드와 환경을 새 컨테이너로 복사하거나 새파일로 복사하지 않음

컨테이너는 이미지에 저장된 환경을 사용하며 그 위에 extra레이어


# 컨테이너 복습 


## Docker Core Concept

컨테이너는 코드와 코드를 실행하는 필요한 환경을 포함한 격리된 박스

컨테이너는 일반적으로 하나의 task에 집중함. 

프론트 엔드 / 데이터베이스 이런식
공유 . 및재생산이 쉬운 작고 가벼운 패키지를 갖는게 컨셉

컨테이너는 이미지로 생성됨 . dockerfile로 만들거나 docker hub에서 가져옴.

 컨테이너는 이미지위의 얇은 부가  레이어

 하나의 동일 이미지에서 다중 컨테이너 실행 가능.

 이미지는 컨테이너에 대한 블루프린트 => 코드와 환경이 포함되어있음 / 읽기전용 

 ## key commands

 docker build -t NAME:TAG . 

name:tag => name&versions of an image / build context

docker run --name NAME --rm -d IMAGE

docker push 및 docker pull 을 통해 공유.
이미지 이름은 docker hub의 리포지토리 이름이어야됨.

docker hub 말고 다른  저장소 사용가능 => 다른 레지스트리의 그 저장소에대한 url 


## 데이터, 볼륨, 네트워킹 
익명 볼륨 => 오버라이트 되는 데이터 저장에 유용함. /  기명 볼륨 => 데이터 계속 유지 

네트워크와 컨테이너 통신 => 컨테이너는 기본적으로 격리되어있는데 컨테이너끼리 보낼때 같은 네트워크 사용하게만드는.

## Docker compose

docker compose up 하면 구성되고 down으로 중지.  
좀 더 복잡한 컨테이너와 복잡한 프로젝트. 다중 컨테이너를 위한 도구 

## 로컬 vs 리모트
배포가리모트 영역.  로컬 시스템의 도커=> 격리/ 캡슐화 재현 / 상호 종속성이없음 / 충돌 x 
배포를 하지않더라도 여전히 놀라운 도구.

격리 캡슐 가장 중요한 재현 가능 환경. 

업데이트도 간단함 => 기존의 컨테이너를 업데이트된 컨테이너로 교체하기만 하면 됨. 

## Deployment 
바인드마운트는 실제로 실행된 컨테이너로 변경된 소스 코드를 확인하기위한 로컬 환경옵션임 프로덕션에서 사용 ㄴ
앱을 배포하고 . 난다음에는 한 머신만으로는 파워가 충분하지않을수있음.
docker run / compose 만으로는 충분하지않음.

통일 호스트에서 여러컨테이너 실행가능.  
실제로 애플리케이션과 하드웨어 요구사항, 수신 트래픽 등에 따라 다름.


멀티스테이지 빌드 => 배포하려는 최종 결과물을 얻기위해 빌드 단계를 요구하는 컨테이너를 빌드 가능.


# 배포 

docker hosting provider 

프로바이더 별로 방법이 다 다름.
aws/azure/googlecloud 3가지가 가장 major
웹 개발 호스팅 머신 러닝 등등 . 을제공 

## 시작 

1. EC2를 만들고 VPC , security group 생성 => 액세스하는 사람 통제 
2. 모든 포트를 WWW에 연결
3. SSH로 연결 => 리모트 머신에 연결하기위한 터미널 기반 접근 방식 /  도커 설치후 실행


## 배포에서 바인드 마운트
배포에서 바인드 마운트 사용안함. 
개발중에는 컨테이너는 물론 런타임 환경을 캡슐화하지만 코드를 캡슐화 할 필요가없음.
컨테이너리빌드 하지않고 최신코드 넣을수있으면 문제가안됨 => 이걸 개발중에 해결한게 바인드마운트

프로덕션에서는 이미지와 컨테이너를 취해 리모트머신으로 이동함. 
컨테이너는 standAlone으로 실행됨  리모트 머신의 주변 설정에 의존하지 않는다는 것이 도커의 아이디어 사상.

이미지와 그 이미지를 기반으로 하는 컨테이너는 단 하나의 소스여야됨.

호스트 머신의 컨테이너 주변에 아무것도 없어도 되야함.

프로덕션용으로 빌드할때 바인딩 마운트 대신 COPY를 사용함. 


sudo yum update -y     //최신버전 업데이트
sudo yum -y install docker 
 
sudo service docker start  // redirecting to bin / docker.service 뜸
 
sudo usermod -a -G docker ec2-user

이거 후 반드시 로그아웃 후 다시 로그인

sudo systemctl enable docker

docker version 으로 사용 가능한지확인 

https://stackoverflow.com/questions/53918841/how-to-install-docker-on-amazon-linux2/61708497#61708497

### 이미지 푸시 
1. 도커파일을 포함한 모든 파일을 리모트 머신에 복사하는방식 => 보내고 build 하고 실행해야됨.
2. 로컬 머신에서 미리 빌드 하고 구축된 이미지 리모트머신에 배포 => 리모트 머신에서 docker run 만 하면됨


docker images 

docker tag ${tagName} ${account/repo} 

docker push ${tag}  

docker login 

퍼블릭 이미지는 로그인할 필요없음.

docker run ${repoName}

permisson error 발생시 sudo 

public ip를 사용하여 확인가능. 그러나 기본적으로 ec2는 www와 모든 연결이 끊어져있음
ssh 로 접근한거아니면 아무도 못봄.

security group에서 이를 통제함. => ec2인스턴스에서 허용되는 트래픽을 제어함.
인바운드 규칙과 아웃바운드 규칙이있고 아웃바운드의 경우 다른곳에있는 대기열로부터 허용되는 트래픽 현재는 모든게 허락되어있기때문에 도커허브에 저장된 이미지 실행가능.

그러나 인바운드의 경우 ssh만 열려있음. aws복습도 하네 개꿀 

### 컨테이너 이미지 관리 및 업데이트

로컬에서 재빌드 -> 태그 지정 -> 푸시 -> 리모트머신에서 중단 -> pull -> re run 

ㅇ 뭐 굳이 적을 필요가있나 싶을정도로 매우 수동적이군

### 수동 배포에서 관리형 서비스로 

 ec2실행하듯이 매니지먼트 서비스를 실행시킬 수 있음. 
 지금 껏 하는방식은 앱이 커지고 들어오는 트래픽이 많아지면 트래픽을 우리 스스로 어떻게든 처리하고 다운되지않도록 보장해야됨
 전문가라면 아주 좋지만 불안정하고 안전하지 않을수도있는 실행을 지속해야됨. 

 여기서 관리형 서비스가 => ECS 
 elastic container service 로 컨테이너 관리를 도와주는 서비스임. 
 ms azure 에도 컨테이너 관리 서비스 있음 ㅇ

 이점은 전체 생성 관리, 업데이트 , 모니터링, 스케일링 이 모든게 단순화된다는 것.

  앱이나 컨테이너를 단순히 배포할거면 이런 관리형 서비스를 사용해서 세부 설정작업에 대한 걱정을 더는게 좋음.

이제 사용하는 서비스의 문법을 사용하고 따라가야됨.



