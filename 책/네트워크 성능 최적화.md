## TCP의 구성요소 

TCP는 신뢰할 수 없는 채널 위에 신뢰성을 구축한 추상 계층이다.
네트워크 통신 구현에 필요한 유실 데이터 재전송, 전송 순서 확인, 혼잡 제어 및 회피 데이터 무결성 확인 같은 복잡한 기능을 투명하게 처리하여 어플리케이션 구현을 한결 쉽게 만들어준다.

TCP스트림의 특징 중하나는 전송된 모든 바이트는 수신된 모든 바이트와 한 치의 오차 없이 동일하며, 클라이언트에서 전송된 바이트 순서대로 도착한다는것.

TCP는 신속한 데이터 전송보다 <b>정확한 데이터의 전송에 더 특화되어있다.</b>

이때문에 웹 성능을 최적화하는데에 어느정도 문제를 야기하기도함.

HTTP 표준은 전송 프로토콜로서 오직 TCP만을 명시하고 있지는 않음. 
HTTP를 유저 데이터 그램 소켓 (UDP)나 우리가 원하는 다른 어떤 프로토콜을 사용해도됨. 

그러나 실제 오늘날 모든 HTTP 트래핏은 전부 TCP를 통해 전송.

TCP자체적으로 훌룡한 기능들이 많아서 ㅇ

이런 연유로 TCP의 핵심 매커님즘을 이해하는것이 웹 성능을 최적화 하는데에 필수적임.
직접적으로 TCP소켓을 다룰일은 거의 없겠지만 애플리케이션 계층에서 선택하는 설계방법에 따라 TCP와 기본적인 네트워크성능이 결정됨.


### 3Way 핸드셰이크
모든 TCP연결은 3-Way 핸드셰이크로부터 시작된다. 

클라이언트와 서버가 애플리케이션 데이터를 주고받으려면 먼저 시작 패킷의 시퀸스 번호와 현재 연결과 관련된 여러 변수의 값을 상호 합의해야함

순서번호는 보안상이유로 양쪽에서 무작위로뽑음.

- SYC
  클라이언트가 무작위로 시퀸스 번호x를 고르고 SYN패킷을 보냄 그밖의 다른 옵션 포함 가능
  다른 TCP플래그나 옵션값들을 포함가능  

- SYN ACK
  서버가 시퀸스 번호 x를 증가시키고 무작위로 y번호를 고름
  서버역시 다른 옵션 추가 가능


- ACK
  클라이언트가 x와 y 값 모두 1씩 증가시키고 마지막 ACK패킷을 보냄으로써 핸드셰이크 종료 


3Way 핸드셰이크가 끝나면 애플리케이션 데이터가 클라와 서버 사이에 오고갈 수 있게됨. 
ACK패킷뒤에 바로 데이터 패킷을 보낼 수 있고 서버는 ACK패킷이 도착해야만 패킷을 보낼 수 있다.

초기절차는 모두 TCP연결에 해당되며 , TCP이용하는 모든 네트워크 애플리케이션의 성능에 중요한 영향을 미침
새로 맺어지는 모든 커넥션은 데이터가 전송되기도전에 클라와 서버간에 왕복레이턴시를 한번 겪게됨.

중요한건 대역폭의 크기는 소요되는 시간에 아무런 영향을 미치지 않는다는것임.

대신에 지연되는 시간은 모두 클라이언트와 서버간의 레이턴시에 의해 발생하며 그 레이턴시는 <b>뉴욕과 런던 사이에 발생하는 전파시간에 의해 정해진다</b>
3-way 핸드셰이크로 인해 발생하는 지연이 크기 때문에, 새로운 TCP커넥션을 맺는 것보다 기존에 연결되어있는 TCP커넥션을 재사용하는것이 TCP에서 작동하는 앱의 최적화에 아주 중요함


- TCP Fast Open

TCP 핸드셰이크는 웹 브라우징 레이턴시의 주된이유. 
여러 호스트로부터 수십개 에서 수백개의 리소스를 얻어오기 위해 짧은 TCP플로가 빈번하게 발생하기 때문 
TCP FAST Open (TFO)은 새로운 TCP 커넥션을 생설할 때마다 발생하는 레이턴시 문젤를 최소화하기 위해 만들어지 메커니즘임.


TFO는 SYN 패킷 안에서 데이터 전송을 가능하게 함으로써 HTTP 트랜잭션 네트워크 레이턴ㅇ시를 15% 만큼 줄였고 전체 페이지로딩 시간은 10% 만큼 레이턴시가 높은 몇몇은 40%까지도 줄일수 있었음.

Linux 3.7+ 커널에서는 서버와 클라이언트 모두 TFO를 지원하고 있으므로 새로운 클라이언트와 서버에게는 좋은 옵션이 될 수있다. 
하지만 TFO 역시 모든 문제를 해결 할 수 있는것은 아님 <b>왕복 패널티 를 줄이는데에는 유용</b>하지만, __특정 조건이 충족되어야만 사용가능__

SYN 패킷 내에는 데이터 페이로드의 크기에 한계가 있기 때문에 특정 타입의 HTTP 요청만 전송할 수 있으며, 암호화된 쿠키를 필요로 하기 떄문에 반복적으로 커넥션을 맺을 때 활용할 수 있다. 


### 혼잡 제어 및 회피 

혼잡 붕괴는 대역폭이 서로 다른 채널로 구성된 네트워크에 영향을 주는 현상이다. 
복잡한 네트워크에서 으레 존재하는 문제임

데이터그램, 프로토콜  그리고 TCP 전송 계층 프로토콜을 함께 사용할 때 이 전송 계층과 데이터그램 계층 간의 상호 작용에 의해 혼잡이 발생한다는것을 발견됨

특히 IP게이트웨이는 소위 말하는 "혼잡 붕괴" 라는 현상에 노출되어있는데 이러한 현상은 __게이트웨이가 갖가지 다른 대역폭을 가진 네트워크와 연결되었을때__ 특히 더 자주 발생한다. 

어떤 호스트의 왕복 시간이 최대 재전송 시간 간격을 초과하게 되면 그 호스트는 네트워크에 지속적으로 같은 데이터그램의 복사본을 보내게됨. => 네트워크에 심각한 문제가 생기게됨

스위칭 노드에 있는 모든 버퍼가 꽉 차게되고 패킷들은 버려질 수 밖에 없게됨. => 도착하는 패킷의 왕복 시간은 최대치까지 올라감

__호스트는 같은 패킷을 여러 번 보내게 되고, 결국은 같은 패킷의 여러 복사점이 도착점에 도착하게됨.__  

이것이 혼잡붕괴.. 


이런 상태는 꽤나 지속되기 때문에, 일단 네트워크가 포화상태에 이르고 나면 버릴 패킷을 고르는 알고리즘이 평이하다는 전제하에 네트워크는 계속해서
_열악한 환경에서 동작하게 된다_


이러한 문제를 해결 하기 위해, 양방향으로 데이터를 보내는 속도를 조절할 수 있는 여러 가지 메커니즘이 TCP에 도입.
그것이 바로 흐름 제어 , 혼잡 제어 그리고 혼잡 회피이다. 

### 흐름제어 (Flow Control)

흐름제어는 송신자가 수신자에게 처리하지 못할 만큼의 많은 데이터를 전송하는 것을 미리 방지하는 메커니즘 
수신자가 데이터를 받짐 못하는 경우 보통 수신자가 다른 데이터를 처리하고 있거나 , 말려있는 데이터가 많거나, 버퍼공간을 충분히 지정해 주지 않는 경우다. 

문제해결을 위해 양쪽의 TCP 커넥션이 각각자신의 리시브 윈도 (rwnd)를 통지하여 수신 데이터를 저장할 버퍼 공간의 크기를 서로에게 알려줌
커넥션이 이루어지면 양쪽에서 자신들의 시스템 기본 설정값 이용하여 rwnd값 초기화. 

일반적으로 웹페이지는 서버에서 클라이언트 쪽으로 대부분의 데이터를 스트리밍 하기 때문에 병목지점이 되는 곳은 클라이언트 쪽일 가능성이 높다. 
하지만 클라이언트가  이미지나 동영상 업로드로 많은 데이터를 서버에게 스트리밍하고있다면 이때에는 서버의 리시브 윈도가 병목지점이 될 것이다. 

어떤 이유로든 서버와 클라중 한곳에서 __수신하고있는 데이터의 양을 감당하지 못할 경우__에는 송신자에게 __리시브 윈도의 크기를 예전보다 줄여 재통지가능__. 

윈도의 크기가 0에 다다르면 현재 버퍼에 남아있는 데이터가 모두 애플리케이션 계층에서 처리될 때까지 새로운 데이터를 수신할 수 없다고 표시됨. 

이러한 작업의 흐름은 모든 TCP 커넥션이 시작할 때부터 끝날 때까지 계속된다. 모든 ACK패킷은 양 끝단의 가장 최근 윈도 크기 (rwnd)
값을 담고있음 . 양(책에서는 야 라고 적혀있는데 오타인듯) 끝의 노드는 이 값을 참고해서 송신자와 수신자의 처리 용량과 성능을 유추해내고 이를 고려해 전송할 데이터양을 유동적으로 조절 가능 => __rwnd값을 참고해서 처리용량과 성능 유추 후 유동적으로 데이터양 조절가능__

- 윈도 스케일링 
원래의 TCP 스펙에서는 리시브 윈도 사이즈를 지정할때 16비트를 할당함. 이것은 __송신자와 수신자가 지정할 수 있는 크기의 최대치가 정해져있__다는 이야기

그런데 실상 이 최대치가 최적의 성능을 내기 위해서는 종종 충분치 않음. 특히 대역폭 지연 곱(bandwidth delay product)이 높은 네트워크에서는 더더욱 그렇다. 

이 문제를 해결하기위해 "TCP 윈도 스케일링" 옵션을 제공하는 RFC 1323이 기술됨.  
이 옵션은 655353 바이트 에서 1기가 바이트까지 늘릴 수 있게 해줌.  이 옵션은 3-Way 핸드셰이크가 일어나는 과정 중에 교환되며 이 옵션이 가지고 있는 값은 차후 ACK에 포함될 16비트 윈도 크기 필드값에 왼쪽 시프트 연산을 해야 할 비트 수를 나타냄.

__오늘날 TCP 윈도 스케일링 옵션은 대부분의 플랫폼에서 기본적으로 활성화 되어있음__ 하지만 중간 노드 , 라우터 , 방화벽 등이 이 설정된 옵션을 다른 값으로 덮어쓰거나 아예 제거 해버릴 수도 있다.  당신이 서버나 클라이언트와 연결을 할 때 허용된 대역폭을 모두 활용할 수 없는 상황이라면 윈도 크기에 대한 정보가 제대로 오가고 있는지 확인할 필요가 있다. 

리눅스 플랫폼에서는 다음의 명령어를 이용하여 윈도 스케일링 옵션을 확인하고 활성화시킬 수 있음

```
$> sysctl net.ipv4. tcp_window_scalling
$> sysctl -w net.ipv4.tcp_window_scalling=1
```

### 느린 시작 

TCP 내에 흐름 제어가 있음에도 불구하고 네트워크 혼잡 붕괴는 1980년 후반에 현실적인 문제로 다가왔다. 

흐름 제어는 송신자가 수신자에게 부담을 주지 않도록 하는 기능을 하고 있었으나, 네트워크 자체에 주는 부담을 막는 메커니즘은 존재하지않았다. 
흐름 제어는 송신자나 수신자 모두 새로운 커넥션이 생성될 때 허용된 대역폭이 얼마 만큼인지 알지 못하기 때문에 ,수시로 변화하는 네트워크 상태에 따라 대역폭을 가늠하고 그에 따라 데이터의 전송속도를 조절하는 메커니즘이 필요했다. 

예를 들어 집에서 원격 서버로부터 대용량의 동영상을 스트리밍한다고 가정할때 그 비디오 스트리밍이 다운링크를 완전히 점유하고있는 상태다.
그런데 홈 네트워크 안에서 또 다른 사용자가 새로운 커넥션을 만들고 소프트웨어를 다운로드하기 시작. 

갑자기 비디오 스트림에게 주어진 다운로드 대역폭이 급격히 줄어들었기 때문에 비디오 서버는 변화된 상황에 따라 데이터 전송률을 조절해야만 한다. 

전송률을 조절하지 않는다면 데이터는 중간에 있는 게이트웨이에서 점점 쌓이게 되고 결국 패킷이 누락되게 되면서 네트워크를 효율적으로 사용할 수 없게 된다.
=> 전송률을 조절하지않으면 쌓이고 패킷이 누락되서 비효율적이된다.

이 문제를 해결하기위한 알고리즘이 느리신작, 혼잡회피, 빠른 재전송, 빠른 복사이다.

이 네가지 알고리즘이 신속하게 TCP 스펙의 필수적인 부분으로 자리 잡았다. 

실제로 이 알고리즘 덕택에 80 90 년대 초에 인터넷 붕괴를 막았다고 믿는 사람들도 있음.


느린 시작을 이해하기 위해서는 이것이 실제로 동작하는 것을 보는게 제일 좋다. 
고객이 런던의 서버에서 파일을 다운로드 하기 위해 접속 => 3-Way 핸드 셰이크 발생. 이때 클라이언트와 서버 모두 자신들의 리시브 윈도(rwnd)크기를 ACK패킷에 실어 서로에게 통지. 마지막 ACK패킷이 출발하고 나면 그때부터 우리는 데이터를 주고 받을 수 있음.

__클라와 서버간의 허용량을 가늠하는 유일한 방법은 실제로 데이터를 교환하면서 허용량을 측정하는 것뿐이다.__ __이게 느린 서버가 하는 일이다.__

일단 서버가 각 TCP 커넥션 마다 새 혼잡 윈도(cwnd) 변수를 만들고 그 값을 시스템에서 정해진 안전한 수치로 설정한다. 

- 혼잡 윈도 크기 (cwnd)
  클라이언트로부터 응답 확인(ACK)신호를 받기 전에 송신자 측에서 지정하는 최대 송신 데이터량.

  cwnd 변수는 송신자와 수신자 간에 값이 교환되거나 서로 통지되지 않는다. 이 경우 cwnd 변수는 서버에서만 private 변수로 관리된다.
  더 나아가 새로운 규칙이 적용되는데. ACK신호를 받지않는 송신자와 수신자 사이에서 이동중인 데이터의 최대치는 rwnd와cwnd 값중 작은 값이 된다.

서버와 클라이언트는 네트워크 상태가 같은 노드에서 항상 변화하는데 어떻게 혼잡 윈도 크기의 최적값을 알아내는 것일까?
매 커넥션 마다 수동으로 윈도 사이즈를 조정하지 않고 어떠한 알고리즘을 사용할 수 있다면 정말 좋을것임.

__문제의 해결법은 커넥션 초반에는 천천히 시작해서 ACK 패킷을 받으면서 점점 윈도 사이즈를 늘려 나가는 것임.__ 이것이 바로 느린 시작
본래 cwnd의 초기값은 1 네트워크 세그먼트로 정해져 있었다.  RFC 2581 에서 이값을 4로 늘렸고 RFC 6928에서 10세그먼트로 다시값을 증가시켰음.

새 TCP 커넥션에서 이동중인 데이터의 최대치는 rwnd와 cwnd의 최소값으로 정해져있음. 그러므로 서버는 클라이언트에게 최대 4개의 세그먼트를 보낼 수 있고, 그 후에는 ACK 신호를 기다려야만 한다.  그러고 나서는 ACK 신호를 받을 때마다 느린 시작 알고리즘이 서버의 cwnd윈도 사이즈를 1 세그만트 만큼 증가시킴. 그 후에는 ACK 신호를 기다려야만 함.  ACK 신호를 받을 때마다 느린 시작 알고리즘이 서버의 cwnd윈도 사이즈를 1세그먼트 만큼 증가시킴. ACK를 받은 패킷 하나당, 두 개의 새로운 패킷을 더 보낼 수 있는것임. 

TCP커넥션에서 이는 보통 __기하급수적 성장 알고리즘__ 으로 알려져 있음. 클라이언트와 서버가 그들 사이의 네트워크에서 사용가능한 대역폭에 신속히 도달하려 하기때문

브라우저 애플리케이션을 개발할 때에 느린 시작(slow-start)을 중요하게 고려해야 할 이유는 무엇일까? __그것은 TCP상에서 동작하는 HTTP나 다른 애플리케이션 프로토콜들은 주어진 대역폭과 관계없이 무조건 이 느린 시작을 거쳐야되기 때문__

모든 TCP 커넥션에서 우리는 곧바로 링크의 최대 허용량을 활용할 수 가없음.

대신 작은 혼잡 윈도 크기부터 시작해서 매번 왕복할때마다 윈도 사이즈를 두 배씩 늘려나가는것이다. 
그 결과 클라와 서버사이의 왕복시간(RTT)과 초기 혼잡 윈도 크기를 이용한 방정식으로 부터 얻을 수 있음.

TCP 커넥션의 초기 처리량은 혼잡윈도 값에 의해 제한되어있고 이는 처리량에 도달하기위해 데이터가 왕복하고 수백초의 레이턴시를 겪어야한다는 뜻으로 클라와 서버가 Mbps이상으로 데이터를 전송할 수 있는 네트워크 성능을 갖췄다 해도 아무소용이없음. 

이게 느린 시작.

혼잡 윈도 크기를 증가시큰데 걸리는 시간을 단축시키기 위해서는 클라이언트와 서버 간의 왕복 시간을 줄이는 방법이 있다.
예를 들어 서버의 위치를 클라이언트에 보다 지역적으로 가까운 곳에 배치시킨다든지. 
혹은 초기 혼잡 윈도 크기 값을 새 RFC 6928에 정의한 10 세그먼트로 늘릴 수도 있음.

느린 시작은 대용량 데이터를 스트리밍하는데에는 큰 영향을 미치지 않는다. 클라이언트와 서버가 단 수백 밀리초 후에 거의 최대 속도로 데이터를 전송할 수 있기 때문.

느린 시작이 미치는 영향은 전송하는 데이터가 클수록 미미해짐.
하지만 대부분의 HTTP 커넥션이 그렇듯, 연결이 짧고 일시적인 경우가 많기 때문에 최대 윈도 크기에 도달하기도 전에 요청이 끝나버리는 일이 발생한다. 

결과적으로 많은 웹 어플리케이션의 성능은 종종 서버와 클라이언트 간의 왕복 시간에 제한되는 경우가 있다.  느린 시작이 최대로 사용할 수 있는 대역폭에 제한을 둠으로써 용량이 작은 데이터를 전송하는 데에는 부작용으로 다가온다. 

- 느린 시작 다시 시작하기
새 커넥션에서 데이터 전송률에 제한을 두는 것 말고도 TCP의 커넥션이 일정시간 동안 유휴 상태(idle)에 머물러 있으면 혼잡 윈도 값을 초기화하는 slow-start-restart(SSR)라는 매커니즘이 존재한다. SSR의 논리는 간단하다. 커넥션이 유휴 상태에 들어가있는동안 네트워크가 어떻게 변해있을지 모르기때문에 , 혼잡을 피하기위해 윈도가 '안전한' 기본값으로 초기화 되는 것이다.
SSR은 여러 번 연달아 유휴 상태에 돌입하는 수명이 긴 TCP 커넥션(long-lived-TCP)에 심각한 영향을 끼칠 수 있다.
HTTP 킵얼라이브(keepalive) 커넥션이 좋은 예다. 결과적으로 서버 측에서 SSR을 비활성화시키는 것이 바람직하다. 리눅스 플랫폼에서는 다음 명령어를 이용하여 SSR의 값을 확인하고 비활성화시킬 수 있다.

```
$> sysctl net.ipv4.tcp_slow_start_after_idle
$> sysctl -w net.ipv4.tcp_slow_start_after_idle=0

```


3-Way 핸드셰이크와 느린 시작 과정이 단순한 HTTP 전송에 끼치는 영향을 좀 더 자세히 들여다 보자.

왕복시간 
클라이언트와 서버사이의 대역폭
클라이언트와 서버 리시브 윈도 
초기 혼잡 윈도
서버 측에서 응답신호를 생성하기 위한 처리시간
패킷 손실 없고, 패킷당 ACK,GET요청이 단일 세그먼트에 들어맞음

<순서>
클라가 SYN 보내고 TCP핸드셰이크 시작
서버가 SYN-ACK로 응답 하고 rwnd 크기 지정
클라가 SYN-ACK에 ACK을 보내고 rwnd 크기를 지정한 후 곧바로 HTTP GET요청
서버가 HTTP 요청을 받음
서버가 응답을 생성한 후 4개의 TCP세그먼트를 보내고 ACK 신호가 오길 기다림 (초기 cwnd 크기는 4다)
클라이언트가 4개의 세그먼트를 받고 각 세그먼트마다 ACK를 보낸다.
서버가 각 ACK마다 cwnd값을 1씩 올리고 8개의 세그먼트를 보낸다
클라가 8개 받고 각 세그먼트마다 ACK 보낸다.
서버각 각 ACK 마다 cwnd값을 1 올리고 나머지 세그먼트를 보낸다.
클라가 나머지 받고 세그먼트 마다 ACK를 보낸다.

연습삼아 cwnd를 4대신 10으로 하면 한번의 왕복시간만큼 레이턴시가 감소하는것을 볼 수 있다 => 성능의 22% 향상으로 볼 수 있음

만약 클라이언트가 기존 TCP 커넥션을 재사용할 수 있었다고 가정하고 한번 더 요청하게되면 3-Way핸드셰이크와 느린 시작 구간의 패널티가 없어졌기 때문에 모든 과정이 275%의 성능향상으로 볼 수 있게된다. 

서버와 클라가 5Mbps의 업스트림의 대역폭을 가졌다는 점에서 TCP 커넥션에서는 아무런 영향을 끼치지않았다. 
그대신 레이턴시와 혼잡 윈도 크기가 주된 제한 요인이였음 .

왕복 시간을 늘릴 수록 두 경우의 성능 차이는 점점 더 벌어짐.
연습삼아 몇 가지 다른 수치록도 시험해봐라 TCP 혼잡 제어의 매너키즘에 대해 감을 잡을 수있도록 킵얼라이브, 파이프라인, 멀티플렉싱과 같은 여러 최적화 방식을 사용하는것이 점점더 꺼려질 수도 있음.

- TCP의 초기 혼잡 윈도 크기 증가

TCP를 사용하는 모든 애플리케이션의 성능을 함께 개선하는 가장 쉬운 방법은 새로운 RFC 6928의 제안대로 서버의 초기 cwnd 크기를 10 세그먼트로 키우는 것이다. 다행히도 많은 운영체제가 증가된 값을 사용하기 위해서 이미 최신 커널로 업데이트를 마쳤다는 사실이다.

여러 문서와 릴리스 노트들을 확인해 보면 알 수 있다.

리눅에서저는 IW 10 이 커널 2.6.39 이상부터는 기본값으로 사용되고 있다. 하지만 여기서 멈추지 말자. 버전 3.2 이상으로 업그레이드 하면 그 밖에 다른 중요한 업데이트의 혜택을 얻을 수 있다. 

### 혼잡 회피 

TCP는 자체 성능을 조절하기 위한 피드백 매커니즘으로써 패킷 손실을 이용하도록 설계되었다는 사실을 인지해야 한다. 
다르게 말하면 패킷 손실이 일어나지 않는 경우는 없고 그보다 패킷 손실이 언제 발생하는가를 파악하는것이 더 중요하다. 
느린 시작(slow-start)은 작은 윈도 크기로 커넥션을 시작한 후, 데이터가 한 바퀴 왕복할 때마다 한 번에 이동하는 데이터 양은 두배로늘어난다.
이 과정은 이동하는 데이터 양이 수신자의 흐름 제어 윈도, 즉 시스템에서 설정된 혼잡 임계치 크기를 넘어서기 전까지 지속되거나 패킷이 손실될 때까지 계속된다. 

그 이후부터는 혼잡 회피알고리즘이 발동한다. 

혼잡 회피에서 암묵적으로 판단하기에 패킷 손실이 일어났다는 것은 네트워크 혼잡이 일어났다는 신호. 
이동 경로의 어딘가에서 정체가 일어난 링크나 라우터가 패킷을 누락시켰을 것이다. 그래서 우리는 네트워크에 부담을 덜어 주고 더이상의 패킷 손실을 막기 위해 윈도 사이즈를 조정해야 하는 것이다.

일단 혼잡 윈도가 리셋되면, 혼잡 회피는 더 이상의 손실을 최소화 하기 위해 얼마나 윈도 크기를 늘려야 할지를 지정한다. 이후 어느시점에서 패킷 손실이 다시 한 번 일어나면 이 과정을 다시 한 번 반복한다. TCP 커넥션의 처리량을 살펴 보다가 톱니모양의 패턴을 한 번이라도 발견한 적이 있다면, 이제 왜 그런 모양이 나왔는지 이해될것이다.  이 패턴의 모습이 네트워크 내의 패킷 손실에 대응하여 혼잡 제어와 회피 알고리즘이 혼잡 윈도 크기를 조정하는 모습인 것이다. 

마지막으로 주목할 만한 점은 연구 분야와 상업 분야 모두에서 혼잡 제어와 회피의 기능을 향상시키기 위한  노력이 활발하다는 사실이다. 

여러 가지 넽ㅡ워크 종류와 다양한 데이터 전송방식 등에 맞는 응용기술 또한 다양하다. 
오늘날 사용하는 플랫폼은 아마 당므 종류 중 한 가지일 것이다. TCP Tahoe와 Reno, TCP Vegas , TCP New Reno , TCP CuBIC(리눅스 기본 설정 ), Compound TCP(Windows 기본 설정) 등이다. 하지만 무엇을 사용하든 혼잡 제어와 회피의 핵심 성능은 모두 동일하다. 

- TCP의 비례속도 감소

  패킷 손실이 일어난 후에 네트워크를 복구하는 최적의 방법을 찾는 일은 결코 쉽지 않다. 만약 복구에 너무 힘을 쏟으면 간헐적으로 손실된 패킷 때문에 커넥션 전체의 처리량에 타격을 받는다.

  하지만 반대로 신속하게 처리하지 못하면 패킷 손실이 더 발생할 수도 있다.

본래 TCP는 지수 감소 가산 증가 (AIMD) 알고리즘을 사용했다. 즉, 패킷 손실이 일어나면 혼합 휜도 크기를 반으로 줄이고, 데이터가 왕복할 때마다 서서히 정해진 수치만큼 윈도를 증가시켜 나가는 것이다. 하지만 많은 경우에 AIMD는 너무 보수적이어서 결국 새로운 알고리즘이 도입됨. 

비례속도 감소 (PRR)는 RFC 6937에 명시된 새로운 알고리즘이다. PRR의 목표는 <b>패킷 손실이 일어났을때 복구하는 속도를 향상시키는것</b>

PRR은 AIMD에 비해 얼마나 개선 되었을까 측정한 결과에 따르면 패킷 손실이 발생한 커넥션에서 평균 레이턴시 3-10%가 감소되었다고함.
PRR은 현재 Linux 3.2+커널에서 기본으로 쓰이는 혼잡회피 알고리즘임. 그래서 더더욱 __서버(커널)을 업그레이드 해야 할 필요가있다__

### 대역폭 지연 곱 (Bandwidth-Delay Product)

TCP에 내장된 혼잡 제어와 혼잡 회피 메커니즘은 성능에 또 다른 영향을 미친다.
송신자와 수신자의 리시브 윈도 최적 값은 왕복 시간과 목표하는 데이터 속도에 따라 달라져야만 한다.

이 논리를 이해하기 위해서는, 먼저 데이터가 ACK를 응답 받지 않은 채 이동할 수 있는 최대 양은 송신자와 수신자 사이의 rwnd와 cwnd 값 중 더 작은 값과 동일하다는 것을 떠올려야 한다. 

현재 상태의 리시브 윈도 값은 매번 ACK신호에 의해 통지되고, 혼잡 윈도는 송신자 측의 혼잡 제어와 회피 알고리즘에 의해 수시로 조정된다. 

만약 송신자와 수신자 둘 중 하나라도 ACK를 받지 않은 상태에서 데이터 최대 전송량을 초파하면, 반대편에서 보낸 패킷에 대한 ACK를 받을 때까지 기다려야 한다. 얼마나 오래 기다려야 할까? 그것은 송신자와 수신자 사이의 데이터 왕복시간에 의해 결정된다.

- 대역폭 지연곱 (Bandwidth-delay product BDP)
 데이터 링크의 허용량과 종단간 지연을 곱한 값. 결과값은 ACK를 받지 않고 이동할 수 있는 데이터의 최대 양

송신자나 수신자 어느 한쪽이 빈번하게 이전에 보낸 패킷의 ACK 신호를 기다려야만 한다면 데이터의 흐름에 공백이 생기게 될 것이다. 결과적으로 커넥션의 최대 처리량을 억제하고 마는 꼴이됨. 이런 문제를 해결하기 위해서 일단 양쪽에서 ACK가 돌아오기를 기다리지 않아도 될 정도로 윈도 사이즈가 넉넉해야 할 것임. 
공백을 없애야 최대 처리량을 얻을 수 있으니까. 결과적으로는 최적의 윈도 사이즈는 데이터의 왕복 시간에 의해서 결정된다.
지정한 윈도 사이즈가 작으면 양쪽 사이에 사용 가능한 대역폭 크기가 얼마가 되든 커넥션 처리량은 윈도 사이즈에 의해 제한되어 버린다. 

우리가 왕복 시간과 양쪽에서 사용할 수 있는 대역폭의 크기를 모두 알고 있다면 최적의 윈도 크기를 구할 수 있다.

TCP에서 사용 가능한 최대 리시브 윈도의 크기는 64kb이며 이를 넘기기 위해서는 윈도 스케일링 옵션을 사용해야만 한다.
다행히도 윈도 크기의 상호 조정은 네트워크 스택에서 자동으로 이루어진다. 단 이것이 가끔 TCP성능의 제한적 요소로 작용할 수 있다. 
이용하는 커넥션이 서버와 클라이언트 모두 높은 전송률을 사용할 수 있음에도 불구하고 왜 사용  가능한 대역폭에 한참 못 미치는 속도로 데이터를 전송하고 있는지 궁금한 적이있다면 이는 작은 윈도 크기때문이다. 

포화 상태에 이른 지점(peer)이 리시브 윈도 크기를 낮출 수도 있고, 의도적인 트래픽 셰이핑(traffic shaping)이 있을 수도있다. 
이 모든 시나리오들이 당신의 커넥션 처리량을 억제할 수 있는 요소들이다.

- 초코속 LAN 내의 대역폭 지연 곱

대역폭 지연 곱(BDP)은 데이터의 왕복 시간과 목표 데이터 전송률에 따라 값이 정해진다. 그래서 전파 지연이 높은 환경의 경우 일반적으로 왕복 시간이 주된 병목이 되지만, 로컬 LAN 환경에서도 얼마든지 병목 요소가 될 수 있다.

### Head-of-Line (HOL) 블로킹

TCP는 신뢰성 없는 채널에서 데이터 전송 신뢰를 보장하는 네트워크 기능을 제공한다. 네트워크를 안정적이고 효율적으로 이용하기 위해 기본적인 패킷 에러검출과 수정, 전송 순서 확인, 손실된 패킷의 재전송, 흐름 제어, 혼잡 제어, 혼잡 회피 등과 같은 메커니즘을 활용한다. 이러한 기능 제공 덕택에 대부분의 애플리케이션이 TCP를 데이터 전송 수단으로써 선호하는것. 

TCP가 널리 쓰이는것은 사실이지만 모든 경우에서 최고라곤 못함

특히나 전송 순서 확인, 안정적인 패킷 전송과 같은 기능은 경우에따라 꼭 필요한게 아니고 불필요한 지연 이나 성능에 영향을 끼칠 수도 
이에대한 이유를 알기 위해선,__모든 TCP 패킷이 전송될 때 고유의 시퀸스 번호를 가지며 수신자에게 주어진 순서대로 전달되어야 한다는 사실__ 을 기억해야함. 

수신자에게 이동 중인 패킷 하나가 소실되면 다른 모든 패킷들은 소실된 패킷이 재전송될 때까지 수신자 쪽 TCP 버퍼에서 대기해야만 함. 
이러한 과정이 TCP 계층 내에서 이루어지기 때문에 애플리케이션에서는 TCP의 데이터 재전송 여부나 큐에 들어있는 패킷 버퍼를 살펴볼 수 없고, 모든 시퀸스가 모두 도착하고 나서야 데이터 접근 가능. 

애플리케이션 입장에서는 그저 소켓에서 데이터를 읽으려 했을 때 전달 지연을 겪게 될 뿐임. 이러한 현상을 TCP HOL이라한다.

=> 이동중에 소실된 패킷이 있으면 전부 다 될때까지 수신자쪽 TCP 버퍼에서  대기해야된다. 

HOL블로킹의 장점은 애플리케이션이 패킷의 재배치나 재조합에 관여할 필요가 없기 때문에 애플리케이션의 코드 자체는 훨씬 간단해진다는것. 

단점은 도착하는 시간이 들쭉 날 쭉해서 레이턴시를 예측하기 어렵다. 이런 현상을 지터(jitter)라고함 성능에 좋지않은 영향을 끼칠 수있음

도착시간이 들쭉 날쭉한것 => jitter

어떤 앱의 경우 전송의 신뢰나 순서가 전혀 필요없을수도있음.  __만약 모든 패킷이 독자적인 메시지라면 순서 필요 ㄴ__ 

__모든 메시지가 이전 메시지를 덮어 쓰게 된다면 전송의 신뢰성 기능 역시 필요 없음__

안타깝지만 TCP에서 이런 설정 변경은 할 수 없다. 무조건 시퀸스 번호 순서대로 전달 

__패킷 전달 순서에 상관이 없고 패킷 손실이 발생해도 별 문제가 없으나, 레이턴시나 지터에 예민한 앱은 UDP와 같은 프로토콜 사용하는게 좋다.__

- 패킷 손실은 필요한가?

TCP에서 최고의 성능을 얻기 위해서는 패킷 손실은 필요한 부분임 누락된 패킷은 피드백 메커니즘의 역할을 하기에, 송신자와 수신자 간에 데이터 전송률을 조정하여 네트워크 부담을 줄이고 레이턴시를 최소화 할 수 있다.
어떤 앱은 패킷 손실이 일어나도 큰 타격을 받지않음 가령 오디오 비디오 게임 상태 업데이트와 같은 경우 앱 데이터는 전송의 신뢰성이 꼭 요구 X 전송 순서 보장될 필요도 X  이것이 WebRTC에서 기본 전송 수단으로 UDP를 사용하는 이유. 

오디오 스트리밍 도중 패킷이 손실되었을 경우 오디오 코덱은 그 부분에 작은 공백을 삽입하고 계속 들어오는 패킷을 처리하면 됨. 
작은 공백은 사용자가 눈치조차 채지 못할 수도 있다.

__패킷을 기다리느라 오디오 출력이 불규칙적으로 멈추면 오히려 사용자에게 더 안좋은 경험__


이상적으로는 모든 데이터를 다 받는게 좋지만 이따금 데이터가 누락된다 하더라도 진해에 지연이 생기는것을 피하기 위해서는 레이턴시가 적게 발생되는 쪽이 좋은 선택이 됨 .


### TCP의 최적화 
TCP는 네트워크를 가장 효율적으로 사용하며, 모든 네트워크 지점(peer)에게 공정하고 합리적으로 설계된 유연한 프로토콜이다. 
그러므로 TCP를 최적화 하는 가장 좋은 방법은 TCP가 현재 네트워크 상태를 어떻게 파악하고, TCP의 상위계층과 하위 계층의 종류와 각종 요구사항에 따라 자신의 동작을 어떻게 조정하는지 살펴보는 것이다. 

무선 네트워크에서는 다른 혼잡 제어 알고리즘이 필요할 수도 있고, 또 다른 애플리케이션은 최고의 성능을 얻기 위해 맞춤형 서비스 품질을 필요로 할 수 있다. 

애플리케이션 마다 요구사항이 다르고 TCP 알고리즘도 각각 설정해야 하는 사항이 많기 때문에 TCP 튜닝과 최적화는 학문적으로나 상업적으로나 철저하게 연구되고 있는 분야다. 

여지껏 다룬 내용 외에도 선택적 응답확인, 지연된 응답확인, 빠른 재전송 등의 매커니즘들이 존재하고 이와 같은 기술들이 각 TCP 세션을 이해하고, 분석하고 조정하는 작업을 더욱 복잡하게 만든다.

알고리즘과 피드백 메커니즘의 세부적인 원리는 계속해서 발전하겠지만 TCP의 핵심 원리와 그것이 미치는 영향은 바뀌지 않는다.

- TCP 3-Way 핸드셰이크는 왕복 시간 한 번 만큼의 레이턴시를 발생시킨다.
- TCP 느린 시작(slow-start)은 커넥션이 새로 만들어질 때 항상 발생한다.
- TCP 흐름 제어와 혼잡 제어는 모든 커넥션의 처리량을 조절한다.
- TCP 처리량은 현재 혼잡 윈도 크기에 의해 결정된다.

결과적으로, TCP 커넥션이 현대의 초고속 네트워크에서 데이터를 전송할 수 있는 속도는 보통 송신자와 수신자 간의 왕복 시간에 의해 제한된다. 또한 대역폭이 계속해서 증가될지라도, 레이턴시는 빛의 속도에 의해 제한되어 있고, 이미 다다를 수 있는 최대 수치에 근접해 있다. 대부분의 경우 __TCP에서의 병목지점은 대역폭이 아니라 레이턴시다.__


### 서버 설정 조정하기 

TCP의 특정 버퍼와 타임아웃 변수를 조정하기 전에, 일단 사용하는 호스트를 최신 시스템 버전으로 업그레이드 하는 것이 좋다. 
TCP를 효과적으로 활용하는 방법과 TCP의 성능을 좌우하는 알고리즘은 갈수록 진화하고 있으나, 이들을 사용하기 위해서는 최신 커널을 설치해야 한다. 
간단히 말해, 서버가 항상 최신으로 업데이트되어 있다면 송신자와 수신자의 TCP 스택 사이에서 최적의 상호작용을 보장받을 수 있다는 뜻이다. 

표먼적으로 보면 서버 커널 버전을 업그레이드하라는 것이 사소한 조언으로 들릴 수도  있지만 , 현실적으로 실행에 옮기는 것이 쉽지만은 않다. 
대부분 많은 서버가 특정 커널 버전에 튜닝되어 있기 때문에 시스템 관리자가 업그레이드 수행을 꺼려하기 때문이다. 

매번 업그레이드하는것이 위험을 안고있기는 하지만 TCP의 성능을 최고로 끌어올리기 위해서는 이것이 당신이 할 수 있는 최고의 투자일 수도 있다.

**최신으로 업그레이드 한 후에는 서버가 다음 기준에 맞춰 설정되어있는지 확인해라**

"TCP의 초기 혼잡 윈도 크기 증가" 
혼잡 윈도의 크기가 크면 TCP가 첫 왕복에 더많은 데이터를 전송할 수 있고 윈도 크기도 신속하게 키울 수 있다. 
_특히 한 번에 많은 데이터가 이동하고, 수명이 짧은 커넥션에게는 매우 중요한 최적화 요소다._

"느린 시작 다시 시작하기 "
_유휴 상태(idle)가 끝난 후에 느린 시작을 비활성화 시키면_ 수명이 길고 한번에 데이터 전송이 많은 TCP 커넥션의 성능을 높일 수 있다. 

"윈도 스케일링"
윈도 스케일링을 활성화하면 윈도 크기를 늘릴 수 있고, 레이턴시가 놆은 커넥션에서 처리량을 개선할 수 있다. 

"TCP Fast Open"
특정 상황에서 첫 SYN 패킷 내에 애플리케이션ㅇ 데이터를 전송할 수 있게 해준다. 
TFO 는 새로 도입된 최적화 기법이기 때문에, 클라이언트와 서버 모두 이 기능을 지원해야만 한다.  => 확인해봐라 쓸 수있는지 

위의 설정들과 더불어 최신 커널이 갖춰진다면 => 모든 TCP 커넥션에서 레이턴시는 낮추고 처리량은 증가시킴으로써 최고의 최적화를 이룰 수 있을 것이다. 

사용하는 애플리케이션의 특에 따라서 커넥션의 고 사용률, 메모리 사용량 등을 최적화 하기 위해 서버의 다른 TCP 설정등을 조정해야 할 수 도있다. 
하지만 이러한 설정은 플랫폼, 앱, 하드에 따라 달라지기 때문에 사용하고 있는 플랫폼의 문서를 잘 살펴봐야 한다. 



### 애플리케이션의 동작 튜닝하기 

TCP의 성능을 튜닝하면 서버와 클라 각 커넥션당 최고의 처리량과 레이턴시를 얻을 수 있다.
하지만 앱이 새 커넥션 혹은 기존 커넥션을 어떻게 사용하느냐가 더 큰 영향을 끼칠 수도 있다.

**
- 비트를 보내지 않는 것보다 빠른 방법은 없다. 즉 더 적은 수의 비트를 전송
- 데이터를 빨리 이동하게 할 수는 없지만 이동거리를 줄일수는 있다.
- TCP커넥션 재사용은 성능향상에 매우 중요하다 

**
불필요한 데이터 전송을 제거하는 것은 물론 가장 좋은 최적화 방법이다. 예를 들어 불필요한 리소스를 제거하거나 적절한 압축 알고리즘을 이용하여 최소 비트 수만을 전송하도록 하는 것이다. 그 다음으로는 서버를 세계 각지에 고루 배치함으로써 데이터를 클라와 지역적으로 가깝게 만들어야 네트워크 왕복 레이턴시를 줄이고 TCP 성능을 크게 향상시킬 수 있다. 
마지막으로, 기존의 TCP 커넥션은 가능한 재사용하여 느린시작이나 다른 혼잡 처리 메커니즘으로 인한 오버헤드를 줄여야한다.

### 성능 체크리스트
TCP 성능을 최적화하는 것은 앱의 종류와 상관없이 모든 새 커넥션을 맺을때 좋은 영향을 미침. 
다음은 최적화 체크리스트

- 서버 커널을 최신 버전으로 업데이트 linux 3.2+
- 혼잡윈도(cwnd) 크기는 10으로 설정
- 유휴 상태 후 느린 시작을 비활성화
- 윈도 스케일링 활성화
- 불필요한 데이터 전송 지양
- 전송데이터 압축
- 서버를 사용자와 가까운곳에 배치
- 기존 TCP커넥션 재활용

## UDP의 구성요소 

UDP User Datagram Protocol 은 기존 TCP/IP프로토콜이 소개된 지 한참 지난 후에 핵심 네트워크 프로토콜에 추가되었다. 
이 시기는 TCP 와IP 의 스펙이 RFC 두개로 분리된 시점과 일치함. 

UDP의 특징은 그것이 가진 다채로운 기능에 있는것이 아니라 많은 기능의 과감한 생략, 즉 단순함에 있다.

UDP는 흔히 null protocol로 불리우며 UDP의 동작 방식을 설명한 RFC 768은 냅킨 한 장에 채워 넣을 만큼 간단함.

- 데이터 그램
  전송 네트워크 계층에서 보장하는 신뢰 기반의 데이터 교환에 이ㅡ존하지 않고, 충분한 양의 정볼르 발신지에서 목적지까지 스스로 운반할 수 있는 독립적인 데이터 개체.

데이터그램과 패킷이란 단어는 혼용하는 경우가 많지만, 그 의미에는 차이가 있다. 
'패킷'이 일반적인 데이터 덩어리르 지칭한다면, '__데이터그램'은 데이터를 전송하는 방식이 불안정하고 전송 실패에대한 notification도 없는 즉 신뢰할 수 없는 서비스를 통해전달되는 패킷을 지칭한다__

사람들은 심지어 UDP에서 User를 Unreliable(신뢰할 수 없는)로 바꿔 해석하기도한다. 

UDP가 사용되는 가장 잘 알려진 예는 브라우저와 인터넷 앱이 의존하고있는 도메인 네임시스템일것이다. 

브라우저는 데이터 교환을  하기전에 먼저 DNS를 통해 컴퓨터의 IP주소를 알아내야된다. 

브라우저가 UDP에 의존하고 있었어도, 이제껏 웹 페이지나 웹 앱이 UDP를 데이터 전송 수단으로 사용하지 않았다.

그러나 Web Real-Time Communication (WebRTC)은 IETF 와 W3C워킹그룹이 함께 개발한 표준 기술로, UDP를 이용해 브라우저 내에서도 음성 통화나 화상 통화, 또는 P2P 통신같은 실시간 커뮤니케이션을 가능케했다. 

WebRTC의 등장으로 UDP도 이제 통용되는 브라우저 전송 수단이 된 것이다. 

### NULL 프로토콜 서비스 
UDP가 왜 'null' 르포토콜이라 불리는지 이해하기 위해서는 , TCP와 UDP 프로토콜의 한 계층 아래에 위치한 IP 에 대해 살펴보아야한다. 

IP계층의 주된 임무는 발신지와 수신지의 주소를 기반으로 데이터그램을 운반하는 것이다. 
먼저 전달하고자 하는 메시지는 IP 패킷 안에 포함되고 이 IP 패킷은 발신지와 수신지의 주소, 그리고 그 밖의 다른 라우팅 파라미터 정보를 담고 있다.

__데이터그램이라는 명칭을 사용하는 이유는 IP 계층이 메시지를 안전하게 전달하지도 않고, 메시지가 전송에 실패했다 하더라도 실패통지를 하지않기때문__


이는 위 계층에게 그대로 해당 네트워크의 불확실성을 드러내는 일이다. 

따라서 __라우팅 노드가 혼잡이나 혹은 다른 어떤 이유로든 IP 패킷을 누락할 경우, IP보다 위 계층에 있는 프로토콜이 이를 탐지에 누락된 패킷을 복구하고 데이터를 재전송해야만한다.__

UDP 프로토콜은 사용자의 메시지를 정의된 패킷 구조에 저장하는데 이 패킷 구조는 발신지 포트 , 수신지 포트 , 패킷의 길이와 체크섬이라는 네 필드로 구성되어있다. 
즉 IP가 패킷을 수신지 호스트로 운반하면, 호스트는 UDP 패킷을 열고 수신지 포트에서 타깃 애플리케이션을 찾아내 메시지를 전달할 수 있다는 뜻이다.


발신지 포트와 체크섬 필드 모두 UDP 데이터그램에서는 선택(option)입력 필드다. 
애플리케이션은 UDP의 헤더 체크섬을 생략할 수 있는데, 이는 모든 에러 탐지와 에러 복구가 그 위 계층 애플리케이션에서 이루어진다는 뜻이다. 
결국 UDP가 하는 일은 IP 위 계층에서 토ㅓㅇ신 호스트의 발신, 수신 애플리케이션 포트를 내장하여 애플리케이션 다중 처리(multiplexing)에 이용하는것 뿐이다. 이를 염두에 두고 UDP가 제공하지않는 서비스는 다음과 같다.

-> 메시지를 무사히 운반할 수 있다는 보장없음
통보(Ack), 재전송, 타임아웃 없음 
-> 메시지를 순서대로 운반할 수 없음
패킷 시퀸스 넘버, 재정렬, head-of-line 블로킹 없음
-> 커넥션 상태 트래킹 없음
커넥션 성립 혹은 종료 매커니즘 없음
-> 혼잡 제어 없음
내장된 클라나 네트워크 피드백 매커니즘없음

TCP는 바이트 스트림 위주의 프로토콜이라 앱의 시작과 끝 범위 명시 안하고 여러 패킷에 걸쳐 전송가능 => 이를 위해서 커넥션 양 쪽 끝에 상태 지정 패킷번호 부여해서 소실되면 재전송

반면 UDP 데이터 그램은 그 범위가 명확 데이터그램 메시지 하나는 IP 패킷 하나에 완전히 포함. 앱이 패킷하나를 읽을때마다 메시지 전체가 수신됨.

데이터ㄷ그램은 TCP 처럼 조각난 채로 운반되는 경우가없다.

UDP는 상태유지안하는 간단한 프로토콜이며. 다른 앱 프로토콜을 호출해서 작동시키는데 적절함.

사실상 거의 모든 프로토콜동장에 관한 디자인 결정 사항을 위 계층의 앱에 위임했다고 볼 수 있다.

그렇다고 지금 당장 TCP를 대신할 새 프로토콜을 개발하러 달려갈 필요는 없음. 

UDP와 수많은 계층에 걸쳐 배치된 미들 장비들 간의 상호작용과 같은 복잡한 문제를 더 고민해야. 

아무리 참신하게 프로토콜을 설계했다 해도, 적절한 기술과 신중한 계획 없이는 결국 허술하게 구현된 TCP에 불과할 것이기 때문이다.

TCP의 알고리즘과 상태기계는 수십년의 수정을 거쳐 발전했기에 수십가지 메커니즘을 능숙하게 재현하는것은 결코 쉽지않을것.


### UDP와 네트워크 주소 변환기 

IPv4 주소의 길이는 단 32비트이므로, 제공할 수 있는 최대 고유 IP 는 총 42억 9천만개에 불과하다. 

이걸 해결하기위해 1994년 중반에 NAT RFC1631 스펙이 처음으로 소개되었다.

이 제안서에서는 네트워크 끝에 NAT기기를 설치해서, 로컬 IP와 포트 번호를 한 개 이상의 고유 공용 IP와 포트 번호에 짝지어 관리하고자 한다. 

이로써 변환기 뒤에 있는 로컬 IP 주소 공간을 다른 네트워크가 재사용할 수 있게 된다. 즉 주소 부족 문제를 해결할 수 있는 것이다. 

NAT 기기는 본래 임시로 도입한 것이었지만, 눈앞에 닥친 주소 부족 문제를 해결함으로써 많은 기업들과 홈 프락시, 라우터 보안기기 방화벽 그밖의 수많은 
하드웨어와 소프트웨어 기기들에게 보편적인 요소로 자리 잡았다. NAT 미들 장비는 더 이상 임시방편이 아니라, 인터넷 인프라에 없어서는 안 될 부분이 된것이다. 

- 예약된 사설 네트워크 범위
IANA는 세계적으로 IP주소를 할당하는 기관이다.
IANA에서는 사설 네트워크가  NAT 기기 뒤에서 사용할 세 범위를 따로 지정해둠.

이 범위가 눈에 익은이유? => 로컬 컴퓨터가 컴퓨터에 IP주소를 할당할 때 이범위를 사용하기 때문임. 
이들은 내부 네트워크에 사용하는 전용 IP주소 이므로, 외부 네트워크와 통신할 때에는 NAT 기기가 이를 자동으로 변환함.

공용 컴퓨터에서는 라우팅 오류나 혼란의 오류가 있어 이 범위 내의 IP주소를 지정받을 수 없다. 

### 연결 상태 타임 아웃 

UDP에서 NAT변환 작업을 할 때 가장 큰 문제는 데이터 운반을 위해 라우팅 테이블을 관리해야한다는 사실.

기본적으로 NAT 미들 장비는 커넥션 상태에 따라 작동하는데, UDP는 커넥션 상태 정보가 없으므로 참조할 수 있는 것이 없다.

이러한 근본적인 차이 때문에 UDP의 데이터그램을 전송할 때에 많은 문제가 발생함. 

또한 수많은 클라이언트가 NAT계층 다음에 위치하고 있기 때문에 문제는 더욱 복잡해짐


각 TCP 커넥션에 존재하는 프로토콜 상태기계에서는 , 커넥션을 맺을 때마다 핸드셰이크로 시작해 애플리케이션 데이터를 전송한 후 잘 정의된 신호 교류로 커넥션을 끝맺는다. 

이러한 흐름에 따라, 각 미들 장비는 커넥션의 상태를 모니터링해가며 필요한 경우 라우팅 엔트리를 만들거나 없앨 수 있다. 
UDP에는 이러한 핸드 셰이크나 커넥션 종료 절차가 없으므로 커넥션 상태 기계를 모니터링 할 필요도 없다. 

아웃바운드 UDP 트래픽을 운반하는 것 자체는 어려운 일이 아니다. 
단, 그에 대한 응답을 라우팅하려면 로컬 수신 호스트의 IP와 포트 값이 변환 테이블에 존재해야 한다.
따라서 변환기는 상태가 없는 UDP의 흐름 상태를 알고 있어야 한다.


뿐만 아니라 변환기는 변환 레코드를 언제 버려야 하는지도 결정해야함.

UDP는 커넥션 종료 시퀸스가 없어서 피어가 통보 없이 언제든 데이터그램 전송을 멈출 수 있다.

그래서 변환기는 UDP 라우팅 레코드를 일정 시간이 지나면 자동으로 폐기하는 방법을 사용.

얼마나 자주 레코드를 버려야  하는지는 변환기의 판매자, 제조업체, 버전, 설정에 따라 달라짐.

결국 UDP에서 장기 세션을 유지하는 가장 좋은 방법은 양방향 킵얼라이브 패킷을 도입해서 정기적으로 모든 NAT기기의 변환 레코드 타이머를 리셋하는 것이다. 

- TCP 타임아웃과 NAT
nat기기에서 굳이 TCP 타임아웃을 추가할 필요는 없다. tcp 프로토콜은 잘 정의된 핸드셰이크와 연결 종료 시퀸스를 따르고있기때문에
변환 레코드를 언제 생성하고 지워야하는지 적절한 시점에 신호를줌.

하지만 실제로는 많은 nat기기가 tcp와 udp세션 모두 비슷한 타임아웃 로직을 적용하고 있다.

결과적으로 tcp도 양방향 킵얼라이브 패킷이 필요한 경우가 생기는 것이다.  만약 tcp커넥션이 아무 이유 없이 끊긴다면 미들 장비의 nat타임아웃 탓일 확률이 높다. 

### NAT통과(Traversal)

